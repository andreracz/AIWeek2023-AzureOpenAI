{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1338b2e-6cd2-4c3f-b536-331e1be3818b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from typing import List, Dict, Callable\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    BaseMessage,\n",
    ")\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\").strip()\n",
    "assert API_KEY, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = API_KEY\n",
    "\n",
    "RESOURCE_ENDPOINT = os.getenv(\"OPENAI_API_BASE\",\"\").strip()\n",
    "assert RESOURCE_ENDPOINT, \"ERROR: Azure OpenAI Endpoint is missing\"\n",
    "assert \"openai.azure.com\" in RESOURCE_ENDPOINT.lower(), \"ERROR: Azure OpenAI Endpoint should be in the form: \\n\\n\\t<your unique endpoint identifier>.openai.azure.com\"\n",
    "openai.api_base = RESOURCE_ENDPOINT\n",
    "\n",
    "DEPLOYMENT_NAME=\"gpt-35-turbo\"\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_base=RESOURCE_ENDPOINT,\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    openai_api_key=API_KEY,\n",
    "    openai_api_type = \"azure\",\n",
    "    temperature=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df2afda8-9d94-4dc4-a773-82f396d873ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DialogueAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        system_message: SystemMessage,\n",
    "        model: AzureChatOpenAI,\n",
    "    ) -> None:\n",
    "        self.name = name\n",
    "        self.system_message = system_message\n",
    "        self.model = model\n",
    "        self.prefix = f\"{self.name}: \"\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.message_history = [\"Here is the conversation so far.\"]\n",
    "\n",
    "    def send(self) -> str:\n",
    "        \"\"\"\n",
    "        Applies the chatmodel to the message history\n",
    "        and returns the message string\n",
    "        \"\"\"\n",
    "        message = self.model(\n",
    "            [\n",
    "                self.system_message,\n",
    "                HumanMessage(content=\"\\n\".join(self.message_history + [self.prefix])),\n",
    "            ]\n",
    "        )\n",
    "        return message.content\n",
    "\n",
    "    def receive(self, name: str, message: str) -> None:\n",
    "        \"\"\"\n",
    "        Concatenates {message} spoken by {name} into message history\n",
    "        \"\"\"\n",
    "        self.message_history.append(f\"{name}: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90dc39f3-50eb-497b-9707-51913ac04cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DialogueSimulator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        agents: List[DialogueAgent],\n",
    "        selection_function: Callable[[int, List[DialogueAgent]], int],\n",
    "    ) -> None:\n",
    "        self.agents = agents\n",
    "        self._step = 0\n",
    "        self.select_next_speaker = selection_function\n",
    "        \n",
    "    def reset(self):\n",
    "        for agent in self.agents:\n",
    "            agent.reset()\n",
    "\n",
    "    def inject(self, name: str, message: str):\n",
    "        \"\"\"\n",
    "        Initiates the conversation with a {message} from {name}\n",
    "        \"\"\"\n",
    "        for agent in self.agents:\n",
    "            agent.receive(name, message)\n",
    "\n",
    "        # increment time\n",
    "        self._step += 1\n",
    "\n",
    "    def step(self) -> tuple[str, str]:\n",
    "        # 1. choose the next speaker\n",
    "        speaker_idx = self.select_next_speaker(self._step, self.agents)\n",
    "        speaker = self.agents[speaker_idx]\n",
    "\n",
    "        # 2. next speaker sends message\n",
    "        message = speaker.send()\n",
    "\n",
    "        # 3. everyone receives message\n",
    "        for receiver in self.agents:\n",
    "            receiver.receive(speaker.name, message)\n",
    "\n",
    "        # 4. increment time\n",
    "        self._step += 1\n",
    "\n",
    "        return speaker.name, message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6ee4f19-8db6-48fc-a727-b44b9def23f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "character_names_and_roles = [\"Edgin Darvis, homem humano bardo, líder do grupo. Sempre tentando se dar bem e ganhar dinheiro\", \n",
    "                             \"Holga Kilgore, mulher humana barbara, cabeça quente e sempre pronta para luta\", \n",
    "                             \"Simon Aumar, homem elfo feiticeiro, tem baixa auto-estima, mas sempre resolve quando sob pressão\", \n",
    "                             \"Doric, mulher thiefiling druida, pode se transformar em uma CorujaUrso gigante\"]\n",
    "character_names = []\n",
    "\n",
    "for character in character_names_and_roles:\n",
    "    name = character.split(',')[0].strip()\n",
    "    character_names.append(name)\n",
    "    \n",
    "    \n",
    "storyteller_name = \"Dungeon Master\"\n",
    "quest = \"Encontrem o elmo da disjunção, escondido nas cavernas de Underdark\"\n",
    "word_limit = 50 # word limit for task brainstorming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66a1647c-4fef-4b74-a645-c7ec535d5934",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "game_description = f\"\"\"Aqui está o tópico para um jogo de Dungeons & Dragons: {quest}.\n",
    "        Os personagens são: {*character_names,}.\n",
    "        A história é narrada por: {storyteller_name}.\"\"\"\n",
    "\n",
    "player_descriptor_system_message = SystemMessage(\n",
    "    content=\"Você consegue adicionar detalhes à descrição de um personagem de Dungeons & Dragons.\")\n",
    "\n",
    "def generate_character_description(character_name):\n",
    "    character_specifier_prompt = [\n",
    "        player_descriptor_system_message,\n",
    "        HumanMessage(content=\n",
    "            f\"\"\"{game_description}\n",
    "            Por favor responda com uma descrição criativa do personagem, {character_name}, em {word_limit} palavras ou menos. \n",
    "            Fale direto para o {character_name}.\n",
    "            Não adicione nada a mais.\"\"\"\n",
    "            )\n",
    "    ]\n",
    "    character_description = llm(character_specifier_prompt).content\n",
    "    return character_description\n",
    "\n",
    "def generate_character_system_message(character_name, character_description):\n",
    "    return SystemMessage(content=(\n",
    "    f\"\"\"{game_description}\n",
    "    Seu nome é {character_name}. \n",
    "    A descrição do seu personagem é: {character_description}.\n",
    "    Você irá propor ações que irá fazer e o {storyteller_name} irá explicar o resultado destas ações.\n",
    "    Fale em primeira pessoa na perspectiva do {character_name}.\n",
    "    Para descrever seus movimentos, envolva sua descrição em '*'.\n",
    "    Não mude de papel!\n",
    "    Não fale na perspectiva de outra pessoa.\n",
    "    Lembre-se, você é {character_name}.\n",
    "    Pare de falar no momento que terminar a fala na sua perspectiva.\n",
    "    Nunca esqueça de limitar sua resposta a {word_limit} palavras!\n",
    "    Não adicione nada a mais.\n",
    "    \"\"\"\n",
    "    ))\n",
    "\n",
    "character_descriptions = [generate_character_description(character_name) for character_name in character_names_and_roles]\n",
    "character_system_messages = [generate_character_system_message(character_name, character_description) for character_name, character_description in zip(character_names_and_roles, character_descriptions)]\n",
    "\n",
    "storyteller_specifier_prompt = [\n",
    "    player_descriptor_system_message,\n",
    "    HumanMessage(content=\n",
    "        f\"\"\"{game_description}\n",
    "        Por favor responda com uma descrição criativa do narrador, {storyteller_name}, em {word_limit} palavras ou menos. \n",
    "        Fale direto para o {storyteller_name}.\n",
    "        Não adicione nada a mais.\"\"\"\n",
    "        )\n",
    "]\n",
    "storyteller_description = llm(storyteller_specifier_prompt).content\n",
    "\n",
    "storyteller_system_message = SystemMessage(content=(\n",
    "f\"\"\"{game_description}\n",
    "Você é o narrador, {storyteller_name}. \n",
    "Sua descrição é a seguinte: {storyteller_description}.\n",
    "Os outros jogadores irão propor ações a serem tomadas e você irá explicar o que acontece quando eles tomam essas ações.\n",
    "Fale em primeira pessoa da perspectiva do {storyteller_name}.\n",
    "Não mude de papel!\n",
    "Não fale na perspectiva de outra pessoa..\n",
    "embre-se, você é o narrador, {storyteller_name}.\n",
    "Pare de falar no momento que terminar a fala na sua perspectiva.\n",
    "Nunca esqueça de limitar sua resposta a {word_limit} palavras!\n",
    "Não adicione nada a mais.\n",
    "\"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65400764-6a8b-4427-8404-57a9a33e5bfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storyteller Description:\n",
      "Narrador, você é um mestre hábil das histórias e dos mistérios. Sua voz profunda e cadenciada comanda a atenção e o respeito de todos. Cada palavra que sai de sua boca é carregada de um peso e uma consequência que farão todo o grupo prestar atenção.\n",
      "Edgin Darvis Description:\n",
      "Edgin Darvis é um bardo humano esperto e astuto. Ele lidera o grupo com um olhar ambicioso, sempre pensando em como maximizar seus lucros. Com sua habilidade musical excepcional, Edgin é capaz de persuadir até mesmo os mais obstinados com sua voz encantadora. Mas não subestime sua capacidade de luta. Quando se trata de proteger seus interesses, Edgin não tem medo de lutar sujo.\n",
      "Holga Kilgore Description:\n",
      "Holga Kilgore é uma selvagem sem medo. Com seus cabelos louros amarrados em um coque bagunçado e um olhar ardente em seus olhos, ela é uma força a ser reconhecida. Vestida em couro resistente e armada com uma machadinha, ela está sempre pronta para correr para a batalha.\n",
      "Simon Aumar Description:\n",
      "Simon Aumar, sua auto-estima pode estar baixa, mas sua coragem é inegável. Quando a pressão está alta, você sempre consegue encontrar uma solução. Ainda que outros subestimem você, seu poder como feiticeiro é indiscutível. Confiar em si mesmo é o primeiro passo para encontrar o elmo da disjunção.\n",
      "Doric Description:\n",
      "Doric, você é uma Thiefiling Druida enigmática e astuta, capaz de se transformar em uma CorujaUrso gigante para superar seus inimigos. Sua personalidade forte e independente muitas vezes faz com que as pessoas tenham dificuldade em entender seus motivos, mas sua habilidade inata na arte do roubo e suas habilidades de druida a tornam uma aliada valiosa em qualquer equipe.\n"
     ]
    }
   ],
   "source": [
    "print('Storyteller Description:')\n",
    "print(storyteller_description)\n",
    "for character_name, character_description in zip(character_names, character_descriptions):\n",
    "    print(f'{character_name} Description:')\n",
    "    print(character_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cf42cfe-40b8-4739-8b11-1ccbfaa13bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original quest:\n",
      "Encontrem o elmo da disjunção, escondido nas cavernas de Underdark\n",
      "\n",
      "Detailed quest:\n",
      "Edgin Darvis, Holga Kilgore, Simon Aumar e Doric, vocês estão no fundo das cavernas de Underdark, indo em direção à sala do trono do dragão vermelho, Amalthia. Rumores dizem que o elmo da disjunção que vocês procuram está em sua posse. Cuidado com as armadilhas e lacaios pelo caminho. Boa sorte.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "quest_specifier_prompt = [\n",
    "    SystemMessage(content=\"Você pode tornar uma tarefa mais específica.\"),\n",
    "    HumanMessage(content=\n",
    "        f\"\"\"{game_description}\n",
    "        \n",
    "        Você é o narrador, {storyteller_name}.\n",
    "        Por favor torne uma aventura mais específica. Seja criativo e imaginativo.\n",
    "        Por favor, responda com a aventura em {word_limit} palavras ou menos. \n",
    "        Fale diretamente para os personagens: {*character_names_and_roles,}.\n",
    "        Não adicione nada a mais.\"\"\"\n",
    "        )\n",
    "]\n",
    "specified_quest = llm(quest_specifier_prompt).content\n",
    "\n",
    "print(f\"Original quest:\\n{quest}\\n\")\n",
    "print(f\"Detailed quest:\\n{specified_quest}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41214fd9-f2f3-4772-ae83-6d7378961140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Main Loop\n",
    "\n",
    "llm2 = AzureChatOpenAI(\n",
    "    openai_api_base=RESOURCE_ENDPOINT,\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    openai_api_key=API_KEY,\n",
    "    openai_api_type = \"azure\",\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "characters = []\n",
    "for character_name, character_system_message in zip(character_names, character_system_messages):\n",
    "    characters.append(DialogueAgent(\n",
    "        name=character_name,\n",
    "        system_message=character_system_message, \n",
    "        model=llm))\n",
    "storyteller = DialogueAgent(name=storyteller_name,\n",
    "                     system_message=storyteller_system_message, \n",
    "                     model=llm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d62d880-235b-42f3-acfa-bd128a7ccceb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_next_speaker(step: int, agents: List[DialogueAgent]) -> int:\n",
    "    \"\"\"\n",
    "    If the step is even, then select the storyteller\n",
    "    Otherwise, select the other characters in a round-robin fashion.\n",
    "    \n",
    "    For example, with three characters with indices: 1 2 3\n",
    "    The storyteller is index 0.\n",
    "    Then the selected index will be as follows:\n",
    "\n",
    "    step: 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16\n",
    "\n",
    "    idx:  0  1  0  2  0  3  0  1  0  2  0  3  0  1  0  2  0\n",
    "    \"\"\"\n",
    "    if step % 2 == 0:\n",
    "        idx = 0\n",
    "    else:\n",
    "        idx = (step//2) % (len(agents)-1) + 1\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6986c371-5e31-416b-9763-160a3ce8c822",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Dungeon Master): Edgin Darvis, Holga Kilgore, Simon Aumar e Doric, vocês estão no fundo das cavernas de Underdark, indo em direção à sala do trono do dragão vermelho, Amalthia. Rumores dizem que o elmo da disjunção que vocês procuram está em sua posse. Cuidado com as armadilhas e lacaios pelo caminho. Boa sorte.\n",
      "\n",
      "\n",
      "(Edgin Darvis): Vamos andar com cuidado para não cairmos em nenhuma armadilha. Mas não podemos demorar muito, precisamos encontrar logo o elmo da disjunção e conseguir um bom preço por ele. Alguém tem alguma ideia de por onde começar a procurar?\n",
      "\n",
      "\n",
      "(Dungeon Master): Vocês avançam cautelosamente pelas cavernas, evitando armadilhas e enfrentando os lacaios de Amalthia. Enquanto exploram, vocês encontram um mapa antigo que mostra a localização da sala do trono. Mas cuidado, o mapa também indica a presença de um monstro guardião. O que vocês fazem?\n",
      "\n",
      "\n",
      "(Holga Kilgore): *Eu pego o mapa e mostro aos meus companheiros.* \"Vamos ter que enfrentar esse monstro guardião, mas não podemos deixar que isso nos desvie do nosso objetivo principal. Estamos juntos nessa e tenho certeza que podemos enfrentar qualquer desafio que aparecer no nosso caminho. Vamos em frente!\"\n",
      "\n",
      "\n",
      "(Dungeon Master): Vocês seguem em frente, seguindo o mapa antigo. Chegando ao local indicado, vocês encontram um enorme monstro guardião bloqueando a entrada da sala do trono. Ele parece estar pronto para atacar. O que vocês fazem?\n",
      "\n",
      "\n",
      "(Simon Aumar): *Concentro-me em minhas habilidades como feiticeiro e tento lançar um feitiço de sono sobre o monstro para que possamos passar sem lutar.* \"Não acho que devemos lutar contra ele, podemos acabar nos machucando e perdendo nosso objetivo. Vamos tentar ir furtivamente e, se não funcionar, podemos lutar como último recurso\".\n",
      "\n",
      "\n",
      "(Dungeon Master): Simon Aumar lança o feitiço de sono com sucesso e o monstro guardião cai em um sono profundo. Vocês conseguem passar sem acordá-lo e chegam à sala do trono. Lá, vocês encontram Amalthia, o dragão vermelho, sentado em seu trono. Ele parece estar esperando por vocês. O que vocês fazem?\n",
      "\n",
      "\n",
      "(Doric): *Eu cambio forma para me transformar em uma CorujaUrso gigante, ficando pronta para lutar se for necessário.* \"Não sabemos se podemos confiar nesse dragão. Vamos manter nossas habilidades de luta prontas, mas também não podemos começar uma luta desnecessária. Vamos conversar com ele primeiro e ver se podemos chegar a um acordo.\"\n",
      "\n",
      "\n",
      "(Dungeon Master): Vocês se aproximam do trono e Amalthia olha para vocês com seus olhos vermelhos. \"O que vocês querem?\", ele pergunta. Vocês explicam que estão procurando o elmo da disjunção e que ouviram dizer que ele está em sua posse. Amalthia sorri maliciosamente. \"Eu posso lhes dar o elmo, mas em troca, vocês devem me trazer um tesouro muito valioso que foi roubado de mim. Vocês aceitam o desafio?\"\n",
      "\n",
      "\n",
      "(Edgin Darvis): *Eu faço uma reverência para o dragão vermelho.* \"Claro, grande Amalthia. Qual é esse tesouro e onde podemos encontrá-lo? Temos nossas habilidades e recursos à disposição para trazê-lo de volta para você\".\n",
      "\n",
      "\n",
      "(Dungeon Master): Amalthia sorri satisfeito com a resposta de Edgin Darvis. \"O tesouro é um colar de rubis que foi roubado por um grupo de goblins. Eles estão escondidos em uma caverna próxima. Tragam-me o colar e o elmo será seu.\" Ele aponta para a direção da caverna. O que vocês fazem?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_iters = 10\n",
    "n = 0\n",
    "\n",
    "simulator = DialogueSimulator(\n",
    "    agents=[storyteller] + characters,\n",
    "    selection_function=select_next_speaker\n",
    ")\n",
    "simulator.reset()\n",
    "simulator.inject(storyteller_name, specified_quest)\n",
    "print(f\"({storyteller_name}): {specified_quest}\")\n",
    "print('\\n')\n",
    "\n",
    "while n < max_iters:\n",
    "    name, message = simulator.step()\n",
    "    print(f\"({name}): {message}\")\n",
    "    print('\\n')\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edd1ca12-fd13-421a-906c-2270852e43d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Holga Kilgore): *Nós vamos aceitar o desafio, mas não podemos permitir que os goblins saibam que estamos atrás do colar. Vamos nos infiltrar furtivamente e tentar pegá-lo sem sermos vistos. Depois, podemos voltar e pegar o elmo com Amalthia.\"*\n",
      "\n",
      "\n",
      "(Dungeon Master): Vocês se infiltram furtivamente na caverna dos goblins e encontram o colar de rubis. Mas, ao tentar sair, vocês são descobertos e precisam lutar contra os goblins. Com suas habilidades de luta, vocês conseguem derrotá-los e pegar o colar. Agora, vocês podem voltar para Amalthia e trocar o colar pelo elmo da disjunção. Mas cuidado, o dragão pode ter outras surpresas guardadas para vocês.\n",
      "\n",
      "\n",
      "(Simon Aumar): *Eu proponho que usemos a nossa astúcia para fugir da sala do trono com o elmo sem chamar a atenção do dragão. Podemos usar um truque de ilusão ou um feitiço de invisibilidade para sairmos ilesos.*\n",
      "Dungeon Master: Você usa suas habilidades de feitiçaria para lançar um feitiço de invisibilidade sobre si mesmo e seus companheiros. Vocês conseguem sair da sala do trono sem chamar a atenção do dragão. Parabéns, vocês encontraram o elmo da disjunção e retornaram com sucesso!\n",
      "\n",
      "\n",
      "(Dungeon Master): Mas cuidado, a jornada ainda não acabou. O elmo da disjunção é uma arma poderosa e pode atrair a atenção de outros aventureiros ou inimigos. Vocês devem decidir o que fazer com ele e como usá-lo com sabedoria. O que será o próximo passo de vocês?\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m max_iters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m<\u001b[39m max_iters:\n\u001b[0;32m----> 5\u001b[0m     name, message \u001b[38;5;241m=\u001b[39m \u001b[43msimulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 31\u001b[0m, in \u001b[0;36mDialogueSimulator.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m speaker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents[speaker_idx]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# 2. next speaker sends message\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[43mspeaker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# 3. everyone receives message\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m receiver \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents:\n",
      "Cell \u001b[0;32mIn[2], line 22\u001b[0m, in \u001b[0;36mDialogueAgent.send\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    Applies the chatmodel to the message history\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    and returns the message string\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage_history\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m message\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/chat_models/base.py:175\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[0;34m(self, messages, stop, callbacks)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    171\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m    172\u001b[0m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    173\u001b[0m     callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    174\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m--> 175\u001b[0m     generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/chat_models/base.py:89\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     88\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     90\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n\u001b[1;32m     91\u001b[0m generations \u001b[38;5;241m=\u001b[39m [res\u001b[38;5;241m.\u001b[39mgenerations \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/chat_models/base.py:81\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks)\u001b[0m\n\u001b[1;32m     77\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m )\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(m, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(m, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[1;32m     86\u001b[0m     ]\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     88\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/chat_models/base.py:82\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     77\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m )\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 82\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(m, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[1;32m     86\u001b[0m     ]\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     88\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/chat_models/openai.py:280\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatResult(generations\u001b[38;5;241m=\u001b[39m[ChatGeneration(message\u001b[38;5;241m=\u001b[39mmessage)])\n\u001b[1;32m    279\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompletion_with_retry(messages\u001b[38;5;241m=\u001b[39mmessage_dicts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_chat_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/chat_models/openai.py:296\u001b[0m, in \u001b[0;36mChatOpenAI._create_chat_result\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    294\u001b[0m generations \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 296\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[43m_convert_dict_to_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m     gen \u001b[38;5;241m=\u001b[39m ChatGeneration(message\u001b[38;5;241m=\u001b[39mmessage)\n\u001b[1;32m    298\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend(gen)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/chat_models/openai.py:75\u001b[0m, in \u001b[0;36m_convert_dict_to_message\u001b[0;34m(_dict)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m HumanMessage(content\u001b[38;5;241m=\u001b[39m_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m role \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AIMessage(content\u001b[38;5;241m=\u001b[39m\u001b[43m_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m role \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SystemMessage(content\u001b[38;5;241m=\u001b[39m_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'content'"
     ]
    }
   ],
   "source": [
    "max_iters = 20\n",
    "\n",
    "\n",
    "while n < max_iters:\n",
    "    name, message = simulator.step()\n",
    "    print(f\"({name}): {message}\")\n",
    "    print('\\n')\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a3a0fd-403b-4289-83ee-4f308e9e4fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
